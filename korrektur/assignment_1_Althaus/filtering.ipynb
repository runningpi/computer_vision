{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcfb5226",
   "metadata": {},
   "source": [
    "# Deep Learning for Computer Vision\n",
    "\n",
    "---\n",
    "\n",
    "**Goethe University Frankfurt am Main**\n",
    "\n",
    "Winter Semester 2022/23\n",
    "\n",
    "<br>\n",
    "\n",
    "## *Assignment 1 (Filtering)*\n",
    "\n",
    "---\n",
    "\n",
    "**Points:** 48/60<br>\n",
    "**Due:** 2.11.2022, 10 am<br>\n",
    "**Contact:** Matthias Fulde ([fulde@cs.uni-frankfurt.de](mailto:fulde@cs.uni-frankfurt.de))<br>\n",
    "\n",
    "---\n",
    "\n",
    "**Your Name:** Maximilian Althaus 7162860\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64171c5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "---\n",
    "\n",
    "- [1 Convolution and Cross Correlation](#1-Convolution-and-Cross-Correlation-(22/30-Points))\n",
    "  - [1.1 Algebraic Properties](#1.1-Algebraic-Properties-(6/10-Points))\n",
    "  - [1.2 Dimension Formula](#1.2-Dimension-Formula-(5/5-Points))\n",
    "  - [1.3 Implementation](#1.3-Implementation-(11/15-Points))\n",
    "- [2 Separable Filters](#2-Separable-Filters-(10/10-Points))\n",
    "  - [2.1 Correctness](#2.1-Correctness-(5/5-Points))\n",
    "  - [2.2 Complexity](#2.2-Complexity-(5/5-Points))\n",
    "- [3 Edge Detection](#3-Edge-Detection-(10/10-Points))\n",
    " - [3.1 Gradient Magnitude](#3.1-Gradient-Magnitude-(5/5-Points))\n",
    " - [3.2 Gradient Direction](#3.2-Gradient-Direction-(5/5-Points))\n",
    "- [4 Image Denoising](#4-Image-Denoising-(6/10-Points))\n",
    "  - [4.1 Gaussian Approximation](#4.1-Gaussian-Approximation-(2/5-Points))\n",
    "  - [4.2 Comparsion](#4.2-Comparsion-(4/5-Points))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31afd2c5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Setup\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook we use the libraries **Matplotlib**, **NumPy** and **OpenCV**. We recommend to use at least the 3.x versions of OpenCV. You can check your version with the statements below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b879423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "# Check installed OpenCV version.\n",
    "cv.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a752faf1",
   "metadata": {},
   "source": [
    "We want Matplotlib figures to appear within the notebook rather than inside a separate window, which is default in some environments, therefore we make use of the `%matplotlib` magic function to set the Matplotlib backend to inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d83e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set default color map and interpolation method for images.\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143a37d",
   "metadata": {},
   "source": [
    "We import a utility function to show images. See `utils.py` for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad532cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d569a33d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Definitions\n",
    "\n",
    "---\n",
    "\n",
    "We define an `error` function to measure the relative difference between two outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040891d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(x, y):\n",
    "    \"\"\"\n",
    "    Calculate the sum of the relative differences.\n",
    "    The absolute differences are scaled with the sum of the absolute values.\n",
    "\n",
    "    Parameters:\n",
    "        - x, y: Arrays with equal shape.\n",
    "\n",
    "    Returns:\n",
    "        - Error between x and y.\n",
    "\n",
    "    \"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "\n",
    "    return np.sum(abs(x - y) / (abs(x) + abs(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795132c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Exercises\n",
    "\n",
    "---\n",
    "\n",
    "### 1 Convolution and Cross Correlation (22/30 Points)\n",
    "\n",
    "---\n",
    "\n",
    "In the lecture, *convolution* and *cross correlation* were introduced as operations that allow to apply a filter to an image.\n",
    "\n",
    "In order to get familiar with them, we're going to show some mathematical properties of the operations and find a formula that describes how these operations transform the dimensions of the input image with respect to their hyperparameters. Finally, we'll implement the operation on our own.\n",
    "\n",
    "However, before we start, let's briefly recap the definitions.\n",
    "\n",
    "---\n",
    "\n",
    "For simplicity, we define the input $I$ and filter $K$ as discrete functions with finite support, rather than as matrices.\n",
    "\n",
    "Then the **cross correlation** operation can be defined as\n",
    "\n",
    "$$\n",
    "    (I \\star K)[m, n]\n",
    "    =\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    K[m + k, n + l].\n",
    "$$\n",
    "\n",
    "The **convolution** operation in the discrete case for real values is exactly the same, except that the filter is flipped along both axes, that is, the order of the entries is reversed. We can define it as\n",
    "\n",
    "$$\n",
    "    (I * K)[m, n]\n",
    "    =\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    K[m - k, n - l].\n",
    "$$\n",
    "\n",
    "Note that the definition of $I$ and $K$ as functions with finite support implies that the infinite sums are absolutely convergent.\n",
    "\n",
    "Regarding the convolution of images with multiple channels, we assume that the number of channels of the input and the filter matches. Then each input channel is convolved with the respective channel of the filter and the per channel outputs are added up to give the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b860f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.1 Algebraic Properties (6/10 Points)\n",
    "\n",
    "---\n",
    "\n",
    "The convolution operation is commutative, associative, and distributive over addition. Furthermore, it is associative with scalar multiplication. The identity element of the operation is the Dirac delta. In this section we want to show, that these claims are actually true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4b1f8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.1 Commutativity (2/2 Points)\n",
    "\n",
    "Given the definition above, show that the convolution operation with input $I$ and filter $K$ is commutative, that is\n",
    "\n",
    "$$\n",
    "    I * K = K * I.\n",
    "$$\n",
    "\n",
    "\\begin{align}\n",
    "    (I * K)[m, n]\n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    K[m - k, n - l]\\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3deb2dc",
   "metadata": {},
   "source": [
    "##### Proof\n",
    "\\begin{align}\n",
    "    (I * K)[m, n]\n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    K[m - k, n - l]\\\\\n",
    "\\end{align}\n",
    "\n",
    "Now let $k' = m-k$ and $l' = n-l$ and through a simple transformation $k=m-k'$ and same for $l$. \n",
    "\n",
    "$$\n",
    "    \\sum_{(m-k') = -\\infty}^\\infty\n",
    "    \\sum_{(n-l') = -\\infty}^\\infty\n",
    "    I[m-k', n-l'] \\,\n",
    "    K[k', l']\\\\\n",
    "$$\n",
    "\n",
    "As $I$ and $K$ are functions with finite support, we can shift the sums by $n$ / $m$ without loosing anything. ($\\infty + n$ is still $\\infty$) Furthermore we calculate the sum in a reverse order, which is possible because of the commutativity of addition.  (otherwise the index would be $-k$ or $-l$)\n",
    "\n",
    "$$\n",
    "    \\sum_{(k') = -\\infty}^\\infty\n",
    "    \\sum_{(l') = -\\infty}^\\infty\n",
    "    I[m-k', n-l'] \\,\n",
    "    K[k', l']\\\\\n",
    "$$\n",
    "\n",
    "Now we can easily rename the indices to $k$ and $l$.\n",
    "\n",
    "$$\n",
    "    \\sum_{(k) = -\\infty}^\\infty\n",
    "    \\sum_{(l) = -\\infty}^\\infty\n",
    "    I[m-k, n-l] \\,\n",
    "    K[k, l] = \\sum_{(k) = -\\infty}^\\infty\n",
    "    \\sum_{(l) = -\\infty}^\\infty\n",
    "     K[k, l] \\,\n",
    "    I[m-k, n-l] = (K*I)[m,n]\n",
    "$$\n",
    "\n",
    "\n",
    "<div style=\"text-align:right\">$\\square$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5dbcfd",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.2 Associativity (2/2 Points)\n",
    "\n",
    "Again let $I$ be the input and let $K_1$ and $K_2$ be two filters. Show that the convolution operation with input $I$ and filters $K_1$ and $K_2$ is associative, that is\n",
    "\n",
    "$$\n",
    "    I * (K_1 * K_2) = (I * K_1) * K_2.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8e82e3",
   "metadata": {},
   "source": [
    "##### Proof\n",
    "\n",
    "\\begin{align}\n",
    "    (K_1 * K_2)[m, n]\n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    K_1[k, l] \\,\n",
    "    K_2[m - k, n - l]\\\\\n",
    "    I * (K_1 * K_2)[m,n] \n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    (K_1* K_2)[m - k, n - l]\\\\ \n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    \\sum_{k' = -\\infty}^\\infty\n",
    "    \\sum_{l' = -\\infty}^\\infty\n",
    "    K_1[k', l'] \\,\n",
    "    K_2[m - k', n - l']\\\\\n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    \\sum_{k' = -\\infty}^\\infty\n",
    "    \\sum_{l' = -\\infty}^\\infty\n",
    "    K_2[k', l'] \\,\n",
    "    K_1[m - k', n - l']\\\\\n",
    "    &= \n",
    "    \\sum_{k' = -\\infty}^\\infty\n",
    "    \\sum_{l' = -\\infty}^\\infty\n",
    "    K_2[k', l'] \\,\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l]\\, \n",
    "    K_1[m - k', n - l']\\\\\n",
    "    &= \n",
    "    \\sum_{k' = -\\infty}^\\infty\n",
    "    \\sum_{l' = -\\infty}^\\infty\n",
    "    K_2[k', l'] \\,\n",
    "    (I * K_1) [m-k',n-l']\\\\\n",
    "    &= ((I* K_1) * K_2)[m,n]\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align:right\">$\\square$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66c2e6",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.3 Distributivity (0/2 Points)\n",
    "\n",
    "Given an input $I$ and filters $K_1$ and $K_2$, show that convolving the input with a sum of filters is the same as adding the results of convolving the input with the individual filters, i.e. show that convolution is distributive over addition, that is\n",
    "\n",
    "$$\n",
    "    I * (K_1 + K_2) = (I * K_1) + (I * K_2).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198c643",
   "metadata": {},
   "source": [
    "##### Proof\n",
    "\n",
    "*Write your proof here.*\n",
    "\n",
    "<div style=\"text-align:right\">$\\square$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f2fc5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.4 Scalar Multiplication (1/1 Point)\n",
    "\n",
    "Let $\\alpha \\in \\mathbb{R}$. Show that the convolution operation with input $I$ and filter $K$ is associative with respect to scalar multiplication, that is\n",
    "\n",
    "$$\n",
    "    (\\alpha I) * K = \\alpha(I * K).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50af412",
   "metadata": {},
   "source": [
    "##### Proof\n",
    "With basic maths we know:\n",
    "$$\n",
    "    ((aI) * K)[m, n]\n",
    "    =\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    aI[k, l] \\,\n",
    "    K[m - k, n - l]=\n",
    "    a\\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    K[m - k, n - l] = a(I * K)\n",
    "$$\n",
    "\n",
    "\n",
    "<div style=\"text-align:right\">$\\square$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698af2c0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.5 Identity (1/1 Point)\n",
    "\n",
    "The identity element of the convolution operation that preserves the input is the Dirac delta, which in the discrete case can be defined as\n",
    "\n",
    "$$\n",
    "    \\delta[m,n]\n",
    "    =\n",
    "    \\begin{cases}\n",
    "        1 & \\text{if} \\enspace m = n = 0 \\\\\n",
    "        0 & \\text{otherwise}.\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "Show that $\\delta$ does not change the input $I$, that is\n",
    "\n",
    "$$\n",
    "    I * \\delta = I.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9fb63",
   "metadata": {},
   "source": [
    "##### Proof\n",
    "\n",
    "$$\n",
    "    (I * \\delta)[m, n]\n",
    "    =\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    \\delta[m - k, n - l]\n",
    "$$\n",
    "The sum just is not 0 if $m = k$ and $n = l$ which is exactly one time the case. So\n",
    "\n",
    "$$\n",
    "    (I * \\delta) [m,n] = I[m,n] * \\delta[0,0] = I[m,n]\n",
    "$$\n",
    "\n",
    "<div style=\"text-align:right\">$\\square$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac4415",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.1.6 Linearity (0/2 Points)\n",
    "\n",
    "Does the discrete convolution operation constitute a linear map, satisfying the additivity and homogeneity conditions?<br>Prove your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f87e50",
   "metadata": {},
   "source": [
    "##### Answer\n",
    "\n",
    "Yes it does. \n",
    "\n",
    "##### Proof\n",
    "\n",
    "The homogeneity can be shown with the same technique like in 1.1.4. \n",
    "\n",
    "<div style=\"text-align:right\">$\\square$</div>\n",
    "\n",
    "*Please provide a complete proof*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8f56c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.2 Dimension Formula (5/5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "In practice we can't compute an infinite sum, so we have to handle the *boundaries* of the given inputs.\n",
    "\n",
    "To preserve the dimensions of the input, we apply **padding** to the image, that means we add pixels to the start and end of each dimension. The size of the padding as well as the values used for the additional pixels are hyperparameters to the convolution and cross correlation operations.\n",
    "\n",
    "The same holds for the **stride**, which determines how far we move the filter in each step.\n",
    "\n",
    "<br>\n",
    "\n",
    "![convolution](images/convolution.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "Take the above figure as an example for strided convolution with padding. ([Dumoulin and Visin](#ref-1))\n",
    "\n",
    "Here, a $3 \\times 3$ filter is applied to a $5 \\times 5$ input image, with 1 pixel padding and a stride of 2, resulting in an output image of size $3 \\times 3$. The first valid filter position is over the top left pixel of the input, due to the applied padding. The filter is then slided across the columns and rows of the input, skipping one pixel in each step, due to the two pixel stride.\n",
    "\n",
    "---\n",
    "\n",
    "Consider an input image $I_\\text{in} \\in \\mathbb{R}^{N \\times N}$ and a filter $K \\in \\mathbb{R}^{M \\times M}$ with $M, N \\in \\mathbb{N}$ and $M$ being odd. In practice, neither the input nor the filter have to be square, but the transformation is the same in each dimension, so for this exercise, we can assume they are.\n",
    "\n",
    "We convolve $I_\\text{in}$ with $K$ to get the output $I_\\text{out}$, that is\n",
    "\n",
    "$$\n",
    "    I_\\text{out} = I_\\text{in} * K.\n",
    "$$\n",
    "\n",
    "For this operation, we assume uniform padding with $P$ pixels. That means the same amount of padding is applied to each of the borders of the image. In addition, we use a stride of $S$ pixels in both directions.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 1.2.1 Task\n",
    "\n",
    "Derive a formula to compute the size $D$ of the output image $I_\\text{out}$ given the size $N$ of the input image $I_\\text{in}$, the size $M$ of the filter $K$, the number of pixels used for padding $P$, and the stride $S$. For each part of the formula, give a brief explanation.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 1.2.2 Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cd57c",
   "metadata": {},
   "source": [
    "$$\n",
    " D= \\lfloor \\frac{N + 2*P - K}{S} \\rfloor+ 1 \n",
    "$$\n",
    "\n",
    "The hight and width are the same, so it is sufficent to compute one of them.\n",
    "\n",
    "The size of the field where the kernal can move is the hight $N$ of the input image $I_{in}$ plus the padding $P$ on the top and the bottom. \n",
    "Now we count the number of steps the kernal can make. Since the kernel size is not 0, we have to subtract the kernel-size from the sum. Becaus the kernal can only do n-1 steps in a n wide space, we have to add 1. (we want wo get the number of positions the kernals visited)\n",
    "\n",
    "The stride reduces the number of possible steps by the factor S, so we have to divide by S.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae6534e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 1.3 Implementation (11/15 Points)\n",
    "\n",
    "---\n",
    "\n",
    "In this exercise, our goal is to implement the convolution and cross correlation operations by ourselves.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 1.3.1 Task\n",
    "\n",
    "Complete the definition of the `filter2D` function below.\n",
    "\n",
    "The function should perform *convolution* or *cross correlation* on the input image and the given filter. The function should work for inputs with one or more channels and produce a single channel output with the same data type as the input image.\n",
    "\n",
    "Depending on the given arguments, the function should [pad](https://numpy.org/doc/stable/reference/generated/numpy.pad.html) the spatial dimensions of the input with zeros before the filter is applied, and it should also work for strides larger than one. It should [flip](https://numpy.org/doc/stable/reference/generated/numpy.flip.html) the kernel horizontally and vertically to perform convolution if requested.\n",
    "\n",
    "Only functions and overloaded operators from NumPy or plain Python are allowed.\n",
    "\n",
    "In order to encourage you to write performant vectorized code, full points are only awarded if no more than two loops are used.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 1.3.2 Solution\n",
    "\n",
    "Enter your solution in the code cell below. Store the output in the given variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934232c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter2D(image, kernel, padding=0, stride=1, flip=False):\n",
    "    \"\"\"\n",
    "    Convolve or correlate a grayscale or color image with a filter kernel.\n",
    "\n",
    "    Notes:\n",
    "        - The number of channels in image and kernel must match.\n",
    "        - The format must be spatial dimensions before channels.\n",
    "        - The output has the same data type as the input.\n",
    "\n",
    "    Parameters:\n",
    "        - image: Grayscale or color image.\n",
    "        - kernel: Filter kernel.\n",
    "        - padding: Uniform zero padding for the input image.\n",
    "        - stride: Uniform stepsize for the kernel.\n",
    "        - flip: Flip the kernel for convolution.\n",
    "\n",
    "    Returns:\n",
    "        - out: The filtered image.\n",
    "\n",
    "    \"\"\"\n",
    "    ############################################################\n",
    "    ##                   START OF YOUR CODE                   ##\n",
    "    ############################################################\n",
    "\n",
    "    if flip == True:\n",
    "        kernel = np.transpose(kernel)\n",
    "    ############################################################\n",
    "    # The transpose of a matrix is not the same as flipping \n",
    "    # along the spatial dimensions                            -2\n",
    "    ############################################################\n",
    "    \n",
    "    #compute kernel size\n",
    "    size = int((len(image)+ 2*padding - len(kernel))/stride )+1 \n",
    "        \n",
    "    #add padding for rgb picture\n",
    "    if type(image[0][0]) != np.float64: \n",
    "    ############################################################\n",
    "    # This does not work for arbitrary input types i.e. float32\n",
    "    # Better: image.ndim == 3                                 -1\n",
    "    ############################################################\n",
    "        image = np.pad(image, pad_width=[(1,1),(1,1),(0,0)], mode='constant', constant_values=0)\n",
    "\n",
    "    #add padding for gray picture\n",
    "    else: \n",
    "        image = np.pad(image, pad_width=[(1,1),(1,1)], mode='constant', constant_values=0)\n",
    "    ############################################################\n",
    "    # Padding should work for arbitray size p                 -1\n",
    "    ############################################################\n",
    "\n",
    "    # compute I*K\n",
    "    out = []\n",
    "    for i in range(0,size*stride, stride):\n",
    "        line = []\n",
    "        for j in range(0,size*stride, stride):\n",
    "            line.append(np.sum(image[i:len(kernel)+i,j:len(kernel)+j]*kernel))\n",
    "\n",
    "        out.append(line)\n",
    "    out = np.array(out)\n",
    "    ############################################################\n",
    "    ##                    END OF YOUR CODE                    ##\n",
    "    ############################################################\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25480dcb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 1.3.3 Test\n",
    "\n",
    "For testing your implementation, two test cases are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf02960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_inputs(x_range, x_shape, k_range, k_shape):\n",
    "    \"\"\"\n",
    "    Generates a test image and a filter.\n",
    "    The pixel values are sampled evenly distributed over the specified ranges.\n",
    "\n",
    "    Parameters:\n",
    "        - x_range: Range for image values.\n",
    "        - x_shape: Shape of the image.\n",
    "        - k_range: Range for filter values.\n",
    "        - k_shape: Shape of the filter.\n",
    "\n",
    "    Returns:\n",
    "        - x: Test image.\n",
    "        - k: Test filter.\n",
    "\n",
    "    \"\"\"\n",
    "    x = np.linspace(*x_range, num=np.prod(x_shape)).reshape(x_shape)\n",
    "    k = np.linspace(*k_range, num=np.prod(k_shape)).reshape(k_shape)\n",
    "\n",
    "    return x, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8675434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function with a grayscale image and unit stride.\n",
    "image, kernel = create_test_inputs(\n",
    "    (-.1, .5), (5, 5),\n",
    "    (-.2, .3), (3, 3)\n",
    ")\n",
    "result = filter2D(image, kernel, padding=1, stride=1)\n",
    "\n",
    "difference = error(result, np.array([\n",
    "    [.0075,     .030625,  .0521875,  .07375,   .0475   ],\n",
    "    [.114375,   .1725,    .18375,    .195,     .10875  ],\n",
    "    [.1753125,  .22875,   .24,       .25125,   .1228125],\n",
    "    [.23625,    .285,     .29625,    .3075,    .136875 ],\n",
    "    [.0075,    -.05375,  -.0603125, -.066875, -.1025   ]\n",
    "]))\n",
    "\n",
    "print(f'Difference is {difference}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e603ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function with a color image and non unit stride.\n",
    "image, kernel = create_test_inputs(\n",
    "    (-.3, .5), (4, 4, 3),\n",
    "    (-.2, .4), (3, 3, 3)\n",
    ")\n",
    "result = filter2D(image, kernel, padding=1, stride=2)\n",
    "difference = error(result, np.array([\n",
    "    [-0.30343699, -0.05081833],\n",
    "    [ 0.89572831,  1.44898527]\n",
    "]))\n",
    "\n",
    "print(f'Difference is {difference}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab79229",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2 Separable Filters (10/10 Points)\n",
    "\n",
    "---\n",
    "\n",
    "A **separable filter** is a filter that can be written as the product of two or more simpler filters.\n",
    "\n",
    "In particular, a two-dimensional separable filter can be decomposed in the product of two one-dimensional filters. The subsequent convolution with the lower dimensional filters can reduce the computational cost significantly.\n",
    "\n",
    "For instance, consider a filter $K \\in \\mathbb{R}^{h \\times w}$. The matrix shaped filter $K$ is separable if we can write it as the outer product of two vector shaped filters $\\mathbf{k}^{(1)} \\in \\mathbb{R}^h$ and $\\mathbf{k}^{(2)} \\in \\mathbb{R}^w$, as in\n",
    "\n",
    "$$\n",
    "    K\n",
    "    \\:=\\:\n",
    "    \\alpha\\beta\n",
    "    \\begin{bmatrix}\n",
    "        k_1^{(1)} k_1^{(2)} & \\cdots & k_1^{(1)} k_w^{(2)} \\\\\n",
    "        \\vdots  & \\ddots & \\vdots  \\\\\n",
    "        k_h^{(1)} k_1^{(2)} & \\cdots & k_h^{(1)} k_w^{(2)}\n",
    "    \\end{bmatrix}\n",
    "    \\:=\\:\n",
    "    \\alpha\n",
    "    \\begin{bmatrix}\n",
    "        k_1^{(1)} \\\\\n",
    "        \\vdots \\\\\n",
    "        k_h^{(1)}\n",
    "    \\end{bmatrix}\n",
    "    \\:\n",
    "    \\beta\n",
    "    \\begin{bmatrix}\n",
    "        k_1^{(2)} & \\cdots & k_w^{(2)}\n",
    "    \\end{bmatrix}\n",
    "    \\:=\\:\n",
    "    \\mathbf{k}^{(1)}\n",
    "    \\,\n",
    "    \\mathbf{k}^{(2)\\top},\n",
    "$$\n",
    "\n",
    "where $\\alpha, \\beta \\in \\mathbb{R}$.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2.1 Correctness (5/5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "Let $I \\in \\mathbb{R}^{H \\times W}$. Show that the convolution of the input $I$ with the filter $K$ is the same as the sequential convolution of $I$ with the simpler filters $\\mathbf{k}^{(1)}$ and $\\mathbf{k}^{(2)}$, that is\n",
    "\n",
    "$$\n",
    "    I * K = (I * \\mathbf{k}^{(1)}) * \\mathbf{k}^{(2)}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f257c",
   "metadata": {},
   "source": [
    "##### Proof\n",
    "Again we interpret $I$ and $K$ as continious functions.\n",
    "\n",
    "From the upper shown associativity we know that  \n",
    "\\begin{align*}\n",
    "    I * K \n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    I[k, l] \\,\n",
    "    K[m - k, n - l]\\\\\n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    K[k, l] \\,\n",
    "    I[m - k, n - l]\\\\\n",
    "\\end{align*}    \n",
    "Now we seperate the kernel into two sub-functions\n",
    "\\begin{align*}\n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    k_1[k] * k_2[l] \\,\n",
    "    I[m - k, n - l]\\\\\n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty\n",
    "    k_1[k] * \n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    k_2[l] \\,\n",
    "    I[m - k, n - l]\\\\\n",
    "    &=\n",
    "    \\sum_{k = -\\infty}^\\infty \n",
    "    \\sum_{l = -\\infty}^\\infty\n",
    "    (I[m - k, n - l] \\, k_2[l] ) * k_1[k]\\\\\n",
    "    &= (I*k^{(2)})*k^{(1)}\n",
    "\\end{align*}\n",
    "\n",
    "By switching the sum indices we get with the same technique \n",
    "\n",
    "$$\n",
    "(I*k^{(1)})*k^{(2)}\n",
    "$$\n",
    "\n",
    "<div style=\"text-align:right\">$\\square$</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7346c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 2.2 Complexity (5/5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "Given the example above of a separable two dimensional filter $K$, derive asymptotic upper bounds for the computational complexity of the convolution $I * K$ and the sequential application of the filters $\\mathbf{k}^{(1)}$ and $\\mathbf{k}^{(2)}$ to the input $I$. Explain your results.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228b5eb3",
   "metadata": {},
   "source": [
    "##### Answer\n",
    "\n",
    "For an image of the size MxN and a kernel of the size hxw, $M * N * h * w$ calculations are needed for $I*K$. (Every line and colums of the image must be multiplicated with every line and column of the kernel.\n",
    "\n",
    "For a sequential application are $M*N*h$ and $M*N*w$ calculations needed. $M*N*h + M*N*w = M*N*(h+w) < M*N*h*w$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c01099",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3 Edge Detection (10/10 Points)\n",
    "\n",
    "---\n",
    "\n",
    "In the lecture we have seen, that we can **detect edges** by approximating the image gradient in horizontal and vertical direction. We remember that for a one-dimensional differentiable function $f(x)$, the gradient corresponds to the derivative, which can be expressed as the limit of the difference quotient\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}x} f(x)\n",
    "    =\n",
    "    \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}\n",
    "    \\mathrel{\\hat{=}}\n",
    "    \\lim_{h \\to 0} \\frac{f(x + h) - f(x - h)}{2h}\\, .\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "However, in the discrete image domain, we can only take differences at one pixel intervals, so we cannot actually compute the gradient at a given image location. But we can adapt the above formula. That is, for a one-dimensional discrete function $f[x]$, we can compute\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\frac{\\text{d}}{\\text{d}x} f[x]\n",
    "    \\approx\n",
    "    \\frac{f[x + 1] - f[x - 1]}{2}\\, .\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Consequently, interpreting an image $I$ as a two variable discrete function mapping indices to pixel intensities, we can approximate the gradient as\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    \\nabla I\n",
    "    =\n",
    "    \\left[\n",
    "        \\frac{\\partial I}{\\partial x},\n",
    "        \\frac{\\partial I}{\\partial y}\n",
    "    \\right]\n",
    "    \\approx\n",
    "    \\left[\n",
    "        \\frac{I[x+1, y] - I[x-1, y]}{2},\n",
    "        \\frac{I[x, y+1] - I[x, y-1]}{2}\n",
    "    \\right].\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "The image gradient encodes the information in which direction the pixel intensity increases the most, and by which rate.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3.1 Gradient Magnitude (5/5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "The amount by which the image intensity is changing when moving into the direction of the fastest increase is given by the **magnitude** of the gradient, which is the $L_2$ norm of the vector, i.e.\n",
    "\n",
    "$$\n",
    "    \\lVert \\nabla I \\rVert\n",
    "    =\n",
    "    \\sqrt{\\left(\\frac{\\partial I}{\\partial x}\\right)^2 + \\left(\\frac{\\partial I}{\\partial y}\\right)^2\\:}.\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 3.1.1 Task\n",
    "\n",
    "We want to use the magnitude of the image gradient to construct a simple edge detector.\n",
    "\n",
    "In order to do this, define two $3 \\times 3$ *correlation* kernels `Kx` and `Ky`, to approximate the image gradient in $x$ and $y$ direction, based on the central difference formula given above. When doing this, you can ignore the normalization by the factor $\\frac{1}{2}$. The resulting filter kernels should look familiar, as they correspond to an operator introduced in the lecture. Which one?\n",
    "\n",
    "Proceed as follows:\n",
    "\n",
    "1. Convert the color image loaded below to grayscale, and cast the data type to `float32`.\n",
    "2. Use the [filter2D](https://docs.opencv.org/4.6.0/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04) function from OpenCV to apply the filters you defined to the image, such that the outputs have the same data type as the input.\n",
    "3. Compute the magnitude of the gradient manually, using only arithmetic functions and operators from NumPy.\n",
    "\n",
    "For this exercise, no loops are allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f618962e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3.1.2 Solution\n",
    "\n",
    "Write your solution in the marked code cell below. Store filter kernels and result in the given variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3472fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read color image without alpha channel.\n",
    "color = cv.imread(root + 'lenna.jpg')\n",
    "\n",
    "# Swap red and blue channel.\n",
    "color = cv.cvtColor(color, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce371d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "##                   START OF YOUR CODE                   ##\n",
    "############################################################\n",
    "#1.\n",
    "gray = cv.cvtColor(color, cv.COLOR_RGB2GRAY)\n",
    "gray = np.float32(gray)\n",
    "\n",
    "#2.\n",
    "Kx = np.array([[-1,0,1], [-1,0,1], [-1,0,1]])\n",
    "Ky = np.array([[-1,-1,-1], [0,0,0], [1,1,1]])\n",
    "\n",
    "verticalLines = cv.filter2D(gray, -1, Kx)\n",
    "horizontalLines = cv.filter2D(gray, -1, Ky)\n",
    "\n",
    "#3.\n",
    "mag = np.sqrt(verticalLines**2 + horizontalLines**2)\n",
    "\n",
    "\n",
    "############################################################\n",
    "##                    END OF YOUR CODE                    ##\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8767a5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3.1.3 Result\n",
    "\n",
    "Display your result with the following statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f72659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show original image and extracted edges.\n",
    "display((12, 6), [\n",
    "    (color, 'Image',     121),\n",
    "    (mag,   'Magnitude', 122)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f42e1d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 3.2 Gradient Direction (5/5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "The direction of the gradient, which is the direction where the image intensity changes the most, can be computed as\n",
    "\n",
    "$$\n",
    "    \\theta\n",
    "    =\n",
    "    \\tan^{-1}\n",
    "    \\left(\n",
    "        \\frac{\\nabla_y I}{\\nabla_x I}\n",
    "    \\right).\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 3.2.1 Task\n",
    "\n",
    "In this exercise, we want to use the direction of the gradient to extract only a subset of edges with a particular orientation from the image, namely those edges roughly parallel to the counterdiagonal ╱ of the image.\n",
    "\n",
    "To approximate the image gradient, we'll use the separable **Sobel** operator. Decompose the $3 \\times 3$ correlation kernels of the Sobel operator into two vector shaped kernels $\\mathbf{k}_1$ and $\\mathbf{k}_2$ that can be sequentially applied to the input image.\n",
    "\n",
    "Proceed as follows:\n",
    "\n",
    "1. Convert the color image loaded below to grayscale, and cast the data type to `float32`.\n",
    "2. Use the [sepFilter2D](https://docs.opencv.org/4.6.0/d4/d86/group__imgproc__filter.html#ga910e29ff7d7b105057d1625a4bf6318d) function from OpenCV to apply the filters you defined to the image, such that the outputs have the same data type as the input.\n",
    "3. This time you can use the function [cartToPolar](https://docs.opencv.org/4.6.0/d2/de8/group__core__array.html#gac5f92f48ec32cacf5275969c33ee837d) to compute both magnitude and angle of the image gradient.\n",
    "4. The [inRange](https://docs.opencv.org/4.6.0/d2/de8/group__core__array.html#ga48af0ab51e36436c5d04340e036ce981) function can be used to create a mask for a suitable angular range.\n",
    "5. Apply the mask with the [bitwise_and](https://docs.opencv.org/4.6.0/d2/de8/group__core__array.html#ga60b4d04b251ba5eb1392c34425497e14) function to the magnitude.\n",
    "\n",
    "The result doesn't have to be perfect. It's enough if you extract the diagonal edges reasonably well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f558aca",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3.2.2 Solution\n",
    "\n",
    "Write your solution in the marked code cell below. Store the kernels, the gradient magnitude and the final result in the given variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read color image without alpha channel.\n",
    "color = cv.imread(root + 'grid.jpg')\n",
    "\n",
    "# Swap red and blue channel.\n",
    "color = cv.cvtColor(color, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56ec42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################################################\n",
    "##                   START OF YOUR CODE                   ##\n",
    "############################################################\n",
    "#1.\n",
    "gray = np.float32(cv.cvtColor(color, cv.COLOR_RGB2GRAY))\n",
    "\n",
    "#2.\n",
    "k1 = np.array([-1, 0, 1], np.float32)\n",
    "k2 = np.array([ 1, 2, 1], np.float32)\n",
    "\n",
    "sobelX = cv.sepFilter2D(gray, -1, k1, k2)\n",
    "sobelY = cv.sepFilter2D(gray, -1, k2, k1)\n",
    "\n",
    "#3.\n",
    "mag, angle = cv.cartToPolar(sobelX, sobelY)\n",
    "\n",
    "#4.\n",
    "angle = np.float32(cv.inRange(angle, 3.2, 4.4))\n",
    "\n",
    "#5.\n",
    "diag = cv.bitwise_and(mag, angle)\n",
    "\n",
    "############################################################\n",
    "##                    END OF YOUR CODE                    ##\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e4737",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 3.2.3 Result\n",
    "\n",
    "Display your result with the following statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e9b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show original image and extracted edges.\n",
    "display((14, 5), [\n",
    "    (color, 'Image',          131),\n",
    "    (mag,   'Magnitude',      132),\n",
    "    (diag,  'Diagonal Edges', 133)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82866e41",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4 Image Denoising (6/10 Points)\n",
    "\n",
    "---\n",
    "\n",
    "In the lecture, different filters for **image denoising** have be introduced. In particular, the box filter, the Gaussian filter, and the median filter.\n",
    "\n",
    "These filters have in common that they are *low pass* filters, meaning that they remove high frequency components from an image, which are characterized by large differences between the intensities of adjacent pixels. Since noise itself has a high frequency, it is reduced by the application of these filters.\n",
    "\n",
    "<br>\n",
    "\n",
    "### 4.1 Approximation (2/5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "In this exercise we'll see that we can approximate a Gaussian filter by the repeated application of box filters. To this end, we'll create a synthetic image and blur the image using both filter types, comparing the results.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 4.1.1 Task\n",
    "\n",
    "As a reference, filter the image created below with a Gaussian filter, using the [GaussianBlur](https://docs.opencv.org/4.6.0/d4/d86/group__imgproc__filter.html#gaabe8c836e97159a9193fb0b11ac52cf1) function of OpenCV.\n",
    "\n",
    "For the Gaussian blur, use a standard deviation of $\\sigma = 20$ and call the function with the `ksize` parameter set to `None`, so that the kernel size is computed automatically from the given $\\sigma$ value.\n",
    "\n",
    "Let $K$ be the number of iterations to apply the box filter to the image. For a good approximation of the Gaussian filter, the following relation between the filter radius $r$ of the box filter, the number of iterations $K$, and the standard deviation $\\sigma$ has been suggested ([Wells](#ref-2)):\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "    r = \\Bigg\\lfloor\\frac{1}{2}\\sqrt{\\frac{12}{K}\\sigma^2 + 1}\\,\\Bigg\\rfloor\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Compute the size of the kernel for the box filter accordingly and use the [blur](https://docs.opencv.org/4.6.0/d4/d86/group__imgproc__filter.html#ga8c45db9afe636703801b0b2e440fce37) function from OpenCV to smooth the image, for $K=1$ and $K=5$.\n",
    "\n",
    "The result of applying the box filter 5 times should look pretty similar to the result for the Gaussian filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac1ae7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.2 Solution\n",
    "\n",
    "Write your solution in the marked code cell below. Store the outputs in the given variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e7be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image size.\n",
    "size = 127\n",
    "\n",
    "# Create empty image to draw on.\n",
    "canvas = np.zeros((size,size), np.uint8)\n",
    "\n",
    "# Draw white circle.\n",
    "image = cv.circle(canvas, center=(size//2,size//2), radius=size//3, color=255, thickness=cv.FILLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626b2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "##                   START OF YOUR CODE                   ##\n",
    "############################################################\n",
    "\n",
    "K_1 = int(0.5* np.sqrt(12/1)*20**2+1)\n",
    "box_1 = cv.blur(image, (K_1, K_1))\n",
    "\n",
    "K_5 = int(0.5* np.sqrt(12/5)*20**2+1)\n",
    "\n",
    "############################################################\n",
    "# You calculated the radius of the kernel, but the diameter\n",
    "# is expected in cv.blur & you got one bracket wrong     -2\n",
    "# should be: int(np.sqrt(12/5*20**2+1))\n",
    "############################################################\n",
    "\n",
    "\n",
    "box_5 = cv.blur(image, (K_5, K_5)) # wo wird der Filter hier 5 mal angewendet?\n",
    "############################################################\n",
    "# You need to apply the box filter 5 times manually       -1\n",
    "############################################################\n",
    "\n",
    "\n",
    "\n",
    "gaussian = cv.GaussianBlur(image, ksize= None, sigmaX = 20, sigmaY=20)\n",
    "\n",
    "############################################################\n",
    "##                    END OF YOUR CODE                    ##\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee78b63",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 4.1.3 Result\n",
    "\n",
    "Display your result with the following statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2ccc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show blurred images alongside original.\n",
    "display((16, 4), [\n",
    "    (image,    'Image',    141),\n",
    "    (box_1,    'Box (1)',  142),\n",
    "    (box_5,    'Box (5)',  143),\n",
    "    (gaussian, 'Gaussian', 144)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47a3a4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 4.2 Comparsion (4/5 Points)\n",
    "\n",
    "---\n",
    "\n",
    "In this exercise we want to compare the introduced filters with respect to the **image denoising** task. In particular, we want to investigate the effects of applying the box, Gaussian, and median filters to an image corrupted with so called salt and pepper noise.\n",
    "\n",
    "Salt and pepper noise is characterized by typically sparse distributions of erroneous pixels that are either totally white or totally black. It can be caused by bit errors during data transmission or errors during analog-digital conversion.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 4.2.1 Task (2/2 Points)\n",
    "\n",
    "In order to make the results comparable, we'll use the *same* filter size of $5 \\times 5$ for all three filters taken into consideration.\n",
    "\n",
    "Proceed as follows:\n",
    "\n",
    "1. Apply a box filter with the given size to the image loaded below, using the `blur` function introduced above.\n",
    "2. Construct a two-dimensional Gaussian filter from two $5 \\times 1$ kernels obtained from the [getGaussianKernel](https://docs.opencv.org/4.6.0/d4/d86/group__imgproc__filter.html#gac05a120c1ae92a6060dd0db190a61afa) function.\n",
    "3. Apply the two-dimensional Gaussian filter to the image using the `filter2D` function.\n",
    "4. Apply a median filter of the same size using the [medianBlur](https://docs.opencv.org/4.6.0/d4/d86/group__imgproc__filter.html#ga564869aa33e58769b4469101aac458f9) function.\n",
    "\n",
    "No loops are allowed in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01139c46",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 4.2.2 Solution\n",
    "\n",
    "Write your solution in the marked code cell below. Store the outputs in the given variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grayscale image.\n",
    "image = cv.imread(root + 'einstein.png', cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb577bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "##                   START OF YOUR CODE                   ##\n",
    "############################################################\n",
    "\n",
    "#1.\n",
    "box = cv.blur(image, (5, 5)) \n",
    "\n",
    "#2.\n",
    "kernel = cv.getGaussianKernel(5,20)*np.transpose(cv.getGaussianKernel(5,20))\n",
    "gaussian = cv.filter2D(image, -1, kernel)\n",
    "\n",
    "median = cv.medianBlur(image, 5)\n",
    "\n",
    "############################################################\n",
    "##                    END OF YOUR CODE                    ##\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65000b96",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### 4.2.3 Result\n",
    "\n",
    "Display your result with the following statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show filtered images alongside original.\n",
    "display((16, 4), [\n",
    "    (image,    'Image',    141),\n",
    "    (box,      'Box',      142),\n",
    "    (gaussian, 'Gaussian', 143),\n",
    "    (median,   'Median',   144)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1142e",
   "metadata": {},
   "source": [
    "#### 4.2.4 Analysis (2/3 Points)\n",
    "\n",
    "Describe your observations. Which filter worked best removing the noise from the image? Explain why this is expected given the properties of this kind of noise and the definitions of the respective filters. Be precise in your formulations and write at least four to five sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db663a",
   "metadata": {},
   "source": [
    "##### Answer\n",
    "\n",
    "The box filter blured the image but does not a good job on removing the noise. You can see that the eye of Einstein is very bright, so the contrast is bad.\n",
    "\n",
    "The Gaussian filter does a better job, but stil has a lot of noise. In the calculation, it gives the pixels in the center of the kernel the highest probability. If this pixel is a salt or pepper pixel, there is a probability that the noise is not removed. However, the image contains more information about the edges and corners than the median filter.\n",
    "\n",
    "The median filter does the best job. The noise is nearly completly removed, but the picture is blured the most. Thereby it looses informations about edges and corners. It is blured, because the kernel computes the mean over all observed pixels. \n",
    "\n",
    "*It calculates the median. Why is this helpful wehn dealing with salt and pepper noise?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2923a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### References\n",
    "\n",
    "---\n",
    "\n",
    "1. <span id=\"ref-1\">V. Dumoulin and F. Visin, \"A guide to convolution arithmetic for deep learning\", 2016.</span>\n",
    "2. <span id=\"ref-2\">W.M. Wells, “Efficient synthesis of Gaussian filters by cascaded uniform filters”, <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>, vol. 8, no. 2, pp. 234–239, 1986.</span>\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
